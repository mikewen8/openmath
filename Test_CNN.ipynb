{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f623ed9-93b9-4b0f-9ade-8efef1cb4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor flow guide book https://archive.org/details/ai-ml/page/24/mode/2up\n",
    "import tensorflow as tf # for ML and we will be using a tensorflow data set/ the mnist number data set\n",
    "#tensorflow guide https://www.tensorflow.org/guide/keras/sequential_model\n",
    "import numpy as np #working with arrays\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import cv2 #for computer vision\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a67d161c-3310-4795-ba01-371b378c69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using my own data this time https://www.youtube.com/watch?v=q7ZuZ8ZOErE\n",
    "#we will still greyscale data reason being it takes the intensity of the light to formulate image recognition processes.\n",
    "#------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b50f083-c675-4a6d-98eb-7cc6eb5d1b5b",
   "metadata": {},
   "source": [
    "\n",
    "When we train our own data\n",
    "using sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    " Assuming you have your data in variables x (images) and y (labels)\n",
    "\n",
    " Split the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    " test_size=0.2 indicates that 20% of the data will be used for testing\n",
    " random_state is used to ensure reproducibility, setting it to a fixed value ensures the same random split each time you run the code\n",
    "\n",
    "for the datapipeline it would probably benefit from using tf.datasets framework for images \n",
    "pandas for statistical data \n",
    "refer to this page:\n",
    "https://www.tensorflow.org/guide/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deb6f413-7a16-4055-87a2-3469a87187b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets normalize the data/grey scaling \n",
    "\"\"\"gray scale pixel has value of  255  normalizing would make it between 0 and 1 \n",
    "it will be scaling things down the value of 125 might look like 0.5\"\"\"\n",
    "\n",
    "\"\"\"axis=-1:\n",
    "When axis=-1, normalization is performed along the last axis of the input data.\n",
    "In the context of a 2D tensor (like a matrix), where the first axis corresponds to rows and the second axis corresponds to columns, axis=-1 implies normalization is performed along the columns.\n",
    "This means that each feature (column) in the input data is independently normalized across the samples.\n",
    "axis=1:\n",
    "When axis=1, normalization is performed along the second axis of the input data.\n",
    "In the context of a 2D tensor, where the first axis corresponds to rows and the second axis corresponds to columns, axis=1 implies normalization is performed along the rows.\n",
    "This means that each sample (row) in the input data is independently normalized across its features.\n",
    "\n",
    "Normalization Along Rows:\n",
    "With axis=0, normalization is applied along each feature (column) across all the samples (rows).\n",
    "Each feature's mean and standard deviation are calculated across all the samples, considering all the values of that feature across all samples.\n",
    "The normalization is then applied to each sample's feature values based on these aggregated statistics.\n",
    "\n",
    "\"\"\"\n",
    "x_train= tf.keras.utils.normalize(x_train, axis= 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95026b70-4fbd-4c0f-8cf0-79aa134f9559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Test data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of what x_train and x_test is\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Test data shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f280cd8-3f46-4917-a93c-e0644779c5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10, 10))\\nfor i in range(25):  # Plotting the first 25 images\\n    plt.subplot(5, 5, i + 1)\\n    plt.imshow(x_train[i], cmap='gray')\\n    plt.axis('off')  # Turn off axis labels\\n    plt.title(f'Label: {y_train[i]}')  # Show the label as the title\\nplt.show()\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot some of the images from the training set\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):  # Plotting the first 25 images\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.title(f'Label: {y_train[i]}')  # Show the label as the title\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "362a1009-6cb1-49ab-94ed-6ee210fffd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nthis is convulitonal one to do larger scaled\\nimport tensorflow as tf\\n\\n# Define input shape\\ninput_shape = (None, None, 1)  # Allow variable input size for height and width, and 1 channel for grayscale\\n\\nmodel = tf.keras.models.Sequential()\\nmodel.add(tf.keras.layers.Input(shape=input_shape))\\nmodel.add(tf.keras.layers.Rescaling(1./255))  # Rescale pixel values to [0, 1]\\n\\n# Add convolutional layers\\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\\n\\n# Global average pooling\\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\\n\\n# Add fully connected layers\\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\\nmodel.add(tf.keras.layers.Dropout(0.5))\\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\\n\\n# Compile the model\\nmodel.compile(optimizer='adam',\\n              loss='sparse_categorical_crossentropy',\\n              metrics=['accuracy'])\\n\\n# Print model summary\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "this is convulitonal one to do larger scaled\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (None, None, 1)  # Allow variable input size for height and width, and 1 channel for grayscale\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "model.add(tf.keras.layers.Rescaling(1./255))  # Rescale pixel values to [0, 1]\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Global average pooling\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb639007-f19b-4dd2-b526-73ef71c0217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape = (28,28))) #flattens the data turns the pixels from 28x28 to a line between 784\n",
    "#flatten turns it from 2-D to a 1-D array\n",
    "\n",
    "#add relu layer and softmax/optimization functions below:\n",
    "model.add(tf.keras.layers.Dense(128,activation = tf.nn.relu)) #model.add(tf.keras.layers.Dense(128,activation = 'relu')) relu follows something simlar to\n",
    "#sigmoid activation relu = f(x)=max(0,x) It returns 0 for all negative inputs and returns the input value for all positive inputs.\n",
    "\n",
    "#relu is the activation function in the dense layer and 128 is the number of units\n",
    "model.add(tf.keras.layers.Dense(128,activation = tf.nn.relu)) # make a second layer \n",
    "model.add(tf.keras.layers.Dense(10,activation = tf.nn.softmax)) # now the softmax layer all the 10 neurons will add up to one \n",
    "#softmax is the output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9314035-15a7-4d37-afb1-d8a9544afa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#how relu works:\\nimport numpy as np\\n\\n# Define a sample input array\\ninput_array = np.array([-2, -1, 0, 1, 2])\\n\\n# Apply ReLU activation function\\noutput_array = np.maximum(0, input_array)\\n\\nprint(\"Input array:\", input_array)\\nprint(\"Output array (ReLU):\", output_array)\\n\\n#Input array: [-2 -1  0  1  2]\\n#Output array (ReLU): [0 0 0 1 2]\\n\\n\\n#how softmax works:\\nimport numpy as np\\n\\ndef softmax(logits):\\n    exp_logits = np.exp(logits)\\n    softmax_scores = exp_logits / np.sum(exp_logits)\\n    return softmax_scores\\n\\n# Example logits (raw scores)\\nlogits = np.array([2.0, 1.0, 0.1])\\n\\n# Compute softmax probabilities\\nprobabilities = softmax(logits)\\n\\nprint(\"Raw Scores (Logits):\", logits)\\nprint(\"Softmax Probabilities:\", probabilities)\\nprint(\"Sum of Probabilities:\", np.sum(probabilities))\\n\\n#Raw Scores (Logits): [2.  1.  0.1]\\n#Softmax Probabilities: [0.65900114 0.24243297 0.09856589]\\n#Sum of Probabilities: 1.0\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#how relu works:\n",
    "import numpy as np\n",
    "\n",
    "# Define a sample input array\n",
    "input_array = np.array([-2, -1, 0, 1, 2])\n",
    "\n",
    "# Apply ReLU activation function\n",
    "output_array = np.maximum(0, input_array)\n",
    "\n",
    "print(\"Input array:\", input_array)\n",
    "print(\"Output array (ReLU):\", output_array)\n",
    "\n",
    "#Input array: [-2 -1  0  1  2]\n",
    "#Output array (ReLU): [0 0 0 1 2]\n",
    "\n",
    "\n",
    "#how softmax works:\n",
    "import numpy as np\n",
    "\n",
    "def softmax(logits):\n",
    "    exp_logits = np.exp(logits)\n",
    "    softmax_scores = exp_logits / np.sum(exp_logits)\n",
    "    return softmax_scores\n",
    "\n",
    "# Example logits (raw scores)\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "\n",
    "# Compute softmax probabilities\n",
    "probabilities = softmax(logits)\n",
    "\n",
    "print(\"Raw Scores (Logits):\", logits)\n",
    "print(\"Softmax Probabilities:\", probabilities)\n",
    "print(\"Sum of Probabilities:\", np.sum(probabilities))\n",
    "\n",
    "#Raw Scores (Logits): [2.  1.  0.1]\n",
    "#Softmax Probabilities: [0.65900114 0.24243297 0.09856589]\n",
    "#Sum of Probabilities: 1.0\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc321a51-7222-430c-9979-1da548cb93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#uses adam optimization make sure you spell the loss function right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190fca79-30f2-4e95-b6a3-3f3c0a8154b0",
   "metadata": {},
   "source": [
    "Cross-entropy is a concept from information theory and is commonly used as a loss function in machine learning, particularly in classification tasks. Mathematically, cross-entropy measures the difference between two probability distributions: the predicted probability distribution and the true probability distribution.\n",
    "\n",
    "Given:\n",
    "\n",
    "p(y): The true probability distribution of the classes. For example, in binary classification,  p(y) could be a one-hot encoded vector representing the true class label.\n",
    "\n",
    "q(y): The predicted probability distribution of the classes. For example, output of a softmax function representing predicted class probabilities.\n",
    "\n",
    "The cross-entropy between \n",
    "p and q, denoted as H(p,q), is defined as:\n",
    "H(p, q) = -\\sum_{i} p(y_i) \\log(q(y_i))\n",
    "Where:\n",
    "\n",
    "i iterates over all classes,\n",
    "\n",
    "p(y_i)  is the true probability of class i\n",
    "\n",
    "q(y_i) is the predicted probability of class i\n",
    "\n",
    "In binary classification, where  p(y) is a one-hot encoded vector with the true class label, the cross-entropy simplifies to the following form:\n",
    "H(p, q) = -[p(y) \\log(q(y)) + (1 - p(y)) \\log(1 - q(y))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af34520e-d1c4-462c-ae48-257ab2b1fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 919us/step - loss: 0.2603 - accuracy: 0.9225\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 2s 909us/step - loss: 0.1069 - accuracy: 0.9669\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 2s 899us/step - loss: 0.0725 - accuracy: 0.9772\n",
      "INFO:tensorflow:Assets written to: handwritten.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: handwritten.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#fit the model pass the training data\n",
    "\n",
    "model.fit(x_train,y_train, epochs=3) \n",
    "# epochs is how many iterations the model will see the data\n",
    "\n",
    "#you can use clusting nearest neighbor instead / convolutional neural netoworks or\n",
    "\n",
    "model.save('handwritten.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd824ab3-ce9f-4790-9d5f-daf76aa3a191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 693us/step - loss: 0.0992 - accuracy: 0.9693\n",
      "Test Loss: 0.09924504905939102\n",
      "Test Accuracy: 0.9692999720573425\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('handwritten.model')\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "#low loss and high accuracy is better \n",
    "#will write to a .pb file with the name of handwritten model \n",
    "#pb stands for proto buffer\n",
    "# protobuffer is data type like json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c56599aa-42cf-4bea-a2fc-99438f58646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "the number is probably 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "the number is probably 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#use os stream and paint to test this model\n",
    "\n",
    "\n",
    "#https://www.youtube.com/watch?v=bte8Er0QhDg need fo figure out why the path isnt working\n",
    "image_number = 0\n",
    "predictions = []\n",
    "\n",
    "while os.path.isfile(f\"Numbers/number{image_number}.png\"):\n",
    "    try:\n",
    "        img = cv2.imread(f\"Numbers/number{image_number}.png\")[:,:,0]\n",
    "        #img = cv2.imread(f\"foldername/label{image_number}.png\")[::0]#we dont care about colors so [:,:,0] will be white on black inverted\n",
    "        #need to invert it to be black on white use numpy to invert the numbers\n",
    "        img = np.invert(np.array([img])) \n",
    "        #img will be an array of a list of img\n",
    "        prediction = model.predict(img)\n",
    "        print(f\"the number is probably {np.argmax(prediction)}\") #argmax gives index of the field of with the highest number which neuron has the highest activation\n",
    "        #zeroth with represent zero the first will represent 1\n",
    "        predictions.append(np.argmax(prediction))\n",
    "        plt.imshow(img[0],cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(\"error\")\n",
    "    finally: #nomatter what this will execute\n",
    "        image_number+=1\n",
    "\n",
    "#if model doesn't work well train with more epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76736d3e-44b0-4f7d-b1d3-81968b6f7e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport cv2\\n\\n# Specify the path to the image file\\nfile_path = \"C:\\\\Users\\\\mikec\\\\openmath\\\\Numbers\\\\number1.png\"\\n\\n# Read the image using OpenCV\\nimg = cv2.imread(file_path)\\n\\n# Check if the image was successfully loaded\\nif img is not None:\\n    # Display the image in a window\\n    cv2.imshow(\\'Number 1\\', img)\\n    # Wait for any key press to close the window\\n    cv2.waitKey(0)\\n    # Close all OpenCV windows\\n    cv2.destroyAllWindows()\\nelse:\\n    print(\"Failed to load the image.\")\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import cv2\n",
    "\n",
    "# Specify the path to the image file\n",
    "file_path = \"C:\\\\Users\\\\mikec\\\\openmath\\\\Numbers\\\\number1.png\"\n",
    "\n",
    "# Read the image using OpenCV\n",
    "img = cv2.imread(file_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if img is not None:\n",
    "    # Display the image in a window\n",
    "    cv2.imshow('Number 1', img)\n",
    "    # Wait for any key press to close the window\n",
    "    cv2.waitKey(0)\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Failed to load the image.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34bfce85-2f35-4e23-85fc-d74251c480cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf272f-4e7e-4f5c-b733-5095642c3200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
